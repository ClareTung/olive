[TOC]

# 高并发编程之基础案例

## 并发编程的问题点

### 背景

* CPU对于数据的计算速度远高于从内存中存取数据的速度。
* CPU和内存的速度不匹配：CPU中增加了缓存。
* CPU和磁盘的速度不匹配：增加了进程和线程。为了使CPU的缓存能够得到更加合理的利用，编译程序对CPU上指令的执行顺序进行了优化。

### 幕后黑手

* 缓存导致的可见性问题

  * **可见性就是说一个线程对共享变量的修改，另一个线程能够立刻看到。**

  * 在单核CPU中，不存在线程的可见性问题。

  * 多核CPU中，每个CPU内核都有自己的缓存。当多个线程在不同的CPU核心上运行时，

    这些线程操作的是不同的CPU缓存。一个线程对缓存的写，对另外一个线程不一定可见。

* 线程切换带来的原子性问题

  * **原子性是指一个或者多个操作在CPU中执行的过程不被中断的特性。**
  * 在并发编程中，往往Java中的一条简单的语句，对应着CPU中的多条指令。
  * count++;
    * 指令1：把变量count从内存加载的CPU寄存器。
    * 指令2：在寄存器中执行count++操作。
    * 指令3：将结果写入缓存（可能是CPU缓存，也可能是内存）。
  * 线程切换可能发生在任何一条CPU指令完成后，而不是程序中的某条语句完成后。
  * CPU能够保证的原子性是CPU指令级别的，而不是编程语言级别的。我们在编写高并发程序时，需要在编程语言级别保证程序的原子性。

* 编译优化带来的有序性问题

  * **有序性是指程序按照代码的既定顺序执行。**
  * 编译器或者解释器为了优化程序的执行性能，有时会改变程序的执行顺序。
  * instance = new SingleInstance();
    * 会有3条CPU指令与其对应：1.分配内存空间。2.初始化对象。3.将instance引用指向内存空间。
    * 正常执行的CPU指令顺序为1—>2—>3，CPU对程序进行重排序后的执行顺序可能为1—>3—>2。

## 可见性问题

### 可见性

* 一个线程对共享变量的修改，另一个线程能够立刻看到。

### 可见性问题

* 一个线程修改了共享变量，另一个线程不能立刻看到，这是由CPU添加了缓存导致的问题。
* 单核CPU不存在可见性问题，无论有多少个线程，同一时刻只会有一个线程能够得到CPU的资源来执行任务。
* 多核CPU，每个CPU都有自己的缓存，多个线程在不同的CPU上执行时，操作的就是不同CPU的缓存。对于其他线程来说，不一定可见。就造成了可见性问题。

## 原子性问题

### 原子性

* 一个或多个操作在CPU中执行的过程不被中断的特性。原子性操作一旦开始运行，就会一直运行到结束为止，中间不会有中断的情况发生。

### 线程切换

* 在并发编程中，线程数目会大于CPU数目，而每个CPU在同一时刻只能被一个线程使用。而CPU资源的分配采用了时间片轮转策略，也就是给每个线程分配一个时间片，线程在这个时间片内占用CPU的资源来执行任务。当占用CPU资源的线程执行完任务后，会让出CPU的资源供其他线程运行，这就是任务切换，也叫做线程切换或者线程的上下文切换。

### 原子性问题

* 指一个或者多个操作在CPU中执行的过程中出现了被中断的情况。
* 正是CPU中对任务的切换机制，导致了并发编程会出现原子性的诡异问题。

## 有序性问题

### 有序性

* 按照代码的既定顺序执行。

### 指令重排序

* 编译器或者解释器为了优化程序的执行性能，有时会改变程序的执行顺序。但是，编译器或者解释器对程序的执行顺序进行修改，可能会导致意想不到的问题！

### 有序性问题

* CPU为了对程序进行优化，会对程序的指令进行重排序，此时程序的执行顺序和代码的编写顺序不一定一致，这就可能会引起有序性问题。

## Java内存模型

* 在内存里，Java内存模型规定了所有的变量都存储在主内存（物理内存）中，每条线程还有自己的工作内存，线程对变量的所有操作都必须在工作内存中进行。不同的线程无法访问其他线程的工作内存里的内容。我们可以使用下图来表示在逻辑上 **线程、主内存、工作内存** 的三者交互关系。

  ![image-20210809142116420](https://cdn.jsdelivr.net/gh/ClareTung/ImageHostingService/img/image-20210809142116420.png)

* 按照需要禁用缓存和编译优化。

  ![image-20210809142627583](https://cdn.jsdelivr.net/gh/ClareTung/ImageHostingService/img/image-20210809142627583.png)

### volatile为什么能保证线程可见

* volatitle关键字不是Java特有的，在C语言中也存在，最原始的意义就是禁用CPU缓存。
* Java中用volatitle对变量修饰，表示不能用CPU缓存，必须从内存中读取和写入。

### happens-before原则

#### 程序次序规则

* 在一个线程中，按照代码的顺序，前面的操作happens-before于后面的任意操作。

#### volatitle变量原则

* 对一个volatitle变量的写操作，h-b于后续对这个变量的读操作。

#### 传递原则

* 如果A h-b B，并且B h-b C，那么A h-b C。

#### 锁定规则

* 对一个锁的解锁操作h-b于后续对这个锁的加锁操作。

#### 线程启动规则

* 如果线程A调用线程B的start()方法来启动线程B，则start()操作h-b于线程B中的任意操作。

#### 线程终结原则

* 线程A等待线程B完成（在线程A中调用线程B的join()方法实现），当线程B完成后（线程A调用线程B的join()方法返回），则线程A能够访问到线程B对共享变量的操作。

#### 线程中断规则

* 对线程interrupt()方法的调用Happens-Before于被中断线程的代码检测到中断事件的发生。

#### 对象终结原则

* 一个对象的初始化完成h-b于它的finalize()方法的开始。

### final关键字

* final关键字修饰的变量，是不会被改变的。

### Java内存模式的底层是实现

* 主要是通过**内存屏障(memory barrier)禁止重排序的**， 即时编译器根据具体的底层体系架构， 将这些内存屏障替换成具体的 CPU指令。 对于编译器而言，内存屏障将限制它所能做的重排序优化。 而对于处理器而言， 内存屏障将会导致缓存的刷新操作。 比如， 对于volatile， 编译器将在volatile字段的读写操作前后各插入一些内存屏障。

## synchronized原理

### 基本使用

* 作用
  * 确保线程互斥的访问同步代码
  * 保证共享变量的修改能够及时可见
  * 有效解决重排序问题
* 用法
  * 修饰普通方法
  * 修饰静态方法
  * 修饰代码块

### 原理

#### 代码块

* monitorenter:
  * 每个对象有一个监视器锁（monitor）。当monitor被占用时就会处于锁定状态，线程执行monitorenter指令时尝试获取monitor的所有权，过程如下：
  * 1、如果monitor的进入数为0，则该线程进入monitor，然后将进入数设置为1，该线程即为monitor的所有者。
  * 2、如果线程已经占有该monitor，只是重新进入，则进入monitor的进入数加1.
  * 3.如果其他线程已经占用了monitor，则该线程进入阻塞状态，直到monitor的进入数为0，再重新尝试获取monitor的所有权。

* monitorexit
  * 执行monitorexit的线程必须是objectref所对应的monitor的所有者。
  * 指令执行时，monitor的进入数减1，如果减1后进入数为0，那线程退出monitor，不再是这个monitor的所有者。其他被这个monitor阻塞的线程可以尝试去获取这个 monitor 的所有权。
* 其实wait/notify等方法也依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.IllegalMonitorStateException的异常的原因。

#### 方法

* ACC_SYNCHRONIZED标示符
* 当方法调用时，调用指令将会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先获取monitor，获取成功之后才能执行方法体，方法执行完后再释放monitor。在方法执行期间，其他任何线程都无法再获得同一个monitor对象。

## 使用互斥锁解决多线程原子性问题

* 对临界区，受保护的资源进行加互斥锁操作

#### synchronized关键字加锁时，Java规定了一些隐式的加锁规则

* 当使用synchronized关键字修饰代码块时，锁定的是实际传入的对象。
* 当使用synchronized关键字修饰非静态方法时，锁定的是当前实例对象this。
* 当使用synchronized关键字修饰静态方法时，锁定的是当前类的Class对象。

```java
private static long count = 0L;
public synchronized long getCount() {
    return count;
}
public synchronized static void incrementCount() {
    count += 1;
}
```

* getCount()和incrementCount()方法是否存在并发问题呢？
  * 对于count资源，是有两个锁分别是this对象和类对象来保护的。但是getCount和incrementCount获取的是两个不同的锁，二者的临界区没有互斥关系，incrementCount方法对count变量的修改无法保证对getCount方法的可见性。**存在并发问题**。

## ThreadLocal

* ThreadLocal是JDK提供的，支持线程本地变量。也就是说，如果我们创建了一个ThreadLocal变量，则访问这个变量的每个线程都会有这个变量的一个本地副本。如果多个线程同时对这个变量进行读写操作时，实际上操作的是线程自己本地内存中的变量，从而避免了线程安全的问题。
* 使用ThreadLocal存储本地变量不具有传递性，也就是说，同一个ThreadLocal在父线程中设置值后，在子线程中是无法获取到这个值的，这个现象说明ThreadLocal中存储的本地变量不具有传递性。

## 并发编程的核心问题

### 分工

* 分工就是将一个比较大的任务，拆分成多个大小合适的任务，交给合适的线程去完成，强调的是**性能**。
* Executor、Fork/Join和Future都是实现分工的一种方式。

### 同步

* 指的是一个线程执行完任务后，如何通知其他的线程继续执行。强调的是**性能**。
* CountDownLatch、 CyclicBarrier 等。

### 互斥

* 同一时刻，只允许一个线程访问共享变量，强调的是线程执行任务的**正确性**。
* synchronized、Lock、ThreadLocal、final关键字等都可以解决互斥的问题。

## ForkJoin

* 将复杂的逻辑拆分成一个个简单的逻辑来并行执行，待每个并行执行的逻辑执行完成后，再将各个结果进行汇总，得出最终的结果数据。
* ForkJoin是由1.7之后提供的多线程并发处理框架。ForkJoin框架的思想是分而治之。
* 什么是分而治之？分而治之就是将一个复杂的计算，按照设定的阈值分解成多个计算，然后将各个计算结果进行汇总。相应的，ForkJoin将复杂的计算当做一个任务，而分解的多个计算则是当做一个个子任务来并行执行。

### 并行和并发

* 并发：同一时刻，只有一个线程能够获得到CPU执行任务，而多个线程被快速的轮换执行。宏观上具有多个线程同时执行的效果，并发不是真正的同时执行。
* 并行：无论何时，多个线程都是在过个CPU核心上同时执行的，是真正的同时执行。

### 分治法

#### 基本思想

* 把一个规模大的问题分为规模较小的子问题，然后分而治之，最后合并子问题的解得到原问题的解。

#### 步骤

*  ①分割原问题；
* ②求解子问题；
* ③合并子问题的解为原问题的解。

#### 典型应用

* 二分搜索、大整数乘法、Strassen矩阵乘法、棋盘覆盖、合并排序、快速排序、线性时间选择、汉诺塔

### ForkJoin框架概述

* 主要用于实现分而治之的算法，特别是分治之后递归调用的函数。
* ForkJoin框架的本质是一个用于并行执行任务的框架， 能够把一个大任务分割成若干个小任务，最终汇总每个小任务结果后得到大任务的计算结果。在Java中，ForkJoin框架与ThreadPool共存，并不是要替换ThreadPool。

### ForkJoin框架原理

* ForkJoin框架是jdk1.7中引入的新特性，它同ThreadPoolExecutor一样，也实现了Executor和ExecutorService接口。
* 它使用**无限队列**来保存需要执行的任务，而线程的数量则是通过构造函数传入，如果没有向构造函数中传入指定的线程数量，那么**当前计算机可用的CPU数量会被设置为线程数量作为默认值**。
* ForkJoinPool主要使用分治法(Divide-and-Conquer Algorithm)来解决问题。ForkJoinPool能够使用相对较少的线程来处理大量的任务。
* ThreadPoolExecutor中的线程无法向任务队列中再添加一个任务并在等待该任务完成之后再继续执行。
* ForkJoinPool就能够解决这个问题，它就能够让其中的线程创建新的任务，并挂起当前的任务，此时线程就能够从队列中选择子任务执行。
* ForkJoinPool能够使用**数量有限的线程**来完成**非常多**的具有**父子关系的任务**，比如使用4个线程来完成超过200万个任务。

### 工作窃取算法

![concurrent](https://cdn.jsdelivr.net/gh/ClareTung/ImageHostingService/img/concurrent.png)

**工作窃取算法的优点：**

* 充分利用线程进行并行计算，并减少了线程间的竞争。

**工作窃取算法的缺点：**

* 在某些情况下还是存在竞争，比如双端队列里只有一个任务时。并且该算法会消耗更多的系统资源，比如创建多个线程和多个双端队列。

**Fork/Join框架局限性：**

* 任务只能使用Fork和Join操作来进行同步机制，如果使用了其他同步机制，则在同步操作时，工作线程就不能执行其他任务了。比如，在Fork/Join框架中，使任务进行了睡眠，那么，在睡眠期间内，正在执行这个任务的工作线程将不会执行其他任务了。
* 在Fork/Join框架中，所拆分的任务不应该去执行IO操作，比如：读写数据文件。
* 任务不能抛出检查异常，必须通过必要的代码来出来这些异常。

### ForkJoin框架中涉及的主要类

#### ForkJoinPool类

* ForkJoinPool类实现了线程池的Executor接口。

### ForkJoinWorkerThread类

* 实现ForkJoin框架中的线程

### ForkJoinTask类

* ForkJoinTask封装了数据及其相应的计算，并且支持细粒度的数据并行。
* ForkJoinTask比线程要轻量，ForkJoinPool中少量工作线程能够运行大量的ForkJoinTask。
* ForkJoinTask类中主要包括两个方法fork()和join()，分别实现任务的分拆与合并。
* fork()方法它并不立即执行任务，而是将任务放入工作队列中。join()方法并不简单的阻塞线程，而是利用工作线程运行其他任务，当一个工作线程中调用join()，它将处理其他任务，直到注意到目标子任务已经完成。

#### ForkJoinTask的三个子类

* RecursiveTask类
  * 有返回结果的ForkJoinTask实现Callable。
* RecursiveActio类
  * 无返回结果的ForkJoinTask实现Runnable。
* CountedCompleter类
  * 在任务完成执行后会触发执行一个自定义的钩子函数。

## CompletableFuture

* 使用`Future`获得异步执行结果时，要么调用阻塞方法get()，要么轮询看isDone()是否为true，这两种方法都不是很好，因为主线程也会被迫等待。
* 从Java8开始引入CompletableFuture，它针对Future做了改进，可以传入回调对象，当异步任务完成或者发生异常时，自动调用回调对象的回调方法。
* CompletableFuture实现了CompletionStage接口和Future接口，前者是对后者的一个扩展，增加了异步回调、流式处理、多个Future组合处理的能力，使Java在处理多任务的协同工作时更加顺畅便利。

### 创建异步任务

#### Future.submit

* 通常的线程池接口类ExecutorService，其中execute方法的返回值是void，即无法获取异步任务的执行状态，3个重载的submit方法的返回值是Future，可以据此获取任务执行的状态和结果。
* 子线程是异步执行的，主线程休眠等待子线程执行完成，子线程执行完成后唤醒主线程，主线程获取任务执行结果后退出。

#### supplyAsync / runAsync

* supplyAsync表示创建带返回值的异步任务的，相当于ExecutorService submit(Callable<T> task) 方法，runAsync表示创建无返回值的异步任务，相当于ExecutorService submit(Runnable task)方法，这两方法的效果跟submit是一样的。
* 这两方法各有一个重载版本，可以指定执行异步任务的Executor实现，如果不指定，默认使用ForkJoinPool.commonPool()，如果机器是单核的，则默认使用ThreadPerTaskExecutor，该类是一个内部类，每次执行execute都会创建一个新线程。

### 异步回调

#### thenApply / thenApplyAsync

* thenApply 表示某个任务执行完成后执行的动作，即回调方法，会将该任务的执行结果即方法返回值作为入参传递到回调方法中。
* thenApplyAsync将任务提交到线程池中异步执行，实际执行的线程可能是另一个线程。
* thenApply是同一个线程执行的。

#### thenAccept / thenRun

* thenAccept 同 thenApply 接收上一个任务的返回值作为参数，但是无返回值；thenRun 的方法没有入参，也没有返回值。

#### exceptionally

* exceptionally方法指定某个任务执行异常时执行的回调方法，会将抛出异常作为参数传递到回调方法中，如果该任务正常执行则会exceptionally方法返回的CompletionStage的result就是该任务正常执行的结果。

#### whenComplete

* whenComplete是当某个任务执行完成后执行的回调方法，会将执行结果或者执行期间抛出的异常传递给回调方法，如果是正常执行则异常为null，回调方法对应的CompletableFuture的result和该任务一致，如果该任务正常执行，则get方法返回执行结果，如果是执行异常，则get方法抛出异常。

#### handle

* 跟whenComplete基本一致，区别在于handle的回调方法有返回值，且handle方法返回的CompletableFuture的result是回调方法的执行结果或者回调方法执行期间抛出的异常，与原始CompletableFuture的result无关了。

### 组合处理

#### thenCombine / thenAcceptBoth / runAfterBoth

*   这三个方法都是将两个CompletableFuture组合起来，只有这两个都正常执行完了才会执行某个任务，区别在于，thenCombine会将两个任务的执行结果作为方法入参传递到指定方法中，且该方法有返回值；thenAcceptBoth同样将两个任务的执行结果作为方法入参，但是无返回值；runAfterBoth没有入参，也没有返回值。注意两个任务中只要有一个执行异常，则将该异常信息作为指定任务的执行结果。

#### applyToEither / acceptEither / runAfterEither

* 这三个方法都是将两个CompletableFuture组合起来，只要其中一个执行完了就会执行某个任务，其区别在于applyToEither会将已经执行完成的任务的执行结果作为方法入参，并有返回值；acceptEither同样将已经执行完成的任务的执行结果作为方法入参，但是没有返回值；runAfterEither没有方法入参，也没有返回值。注意两个任务中只要有一个执行异常，则将该异常信息作为指定任务的执行结果。

#### thenCompose

* thenCompose方法会在某个任务执行完成后，将该任务的执行结果作为方法入参然后执行指定的方法，该方法会返回一个新的CompletableFuture实例，如果该CompletableFuture实例的result不为null，则返回一个基于该result的新的CompletableFuture实例；如果该CompletableFuture实例为null，则，然后执行这个新任务。

#### allOf / anyOf

* allOf返回的CompletableFuture是多个任务都执行完成后才会执行，只有有一个任务执行异常，则返回的CompletableFuture执行get方法时会抛出异常，如果都是正常执行，则get返回null。
* *allof等待所有任务执行完成才执行cf4，如果有一个任务异常终止，则cf4.get时会抛出异常，都是正常执行，cf4.get返回null*
* *anyOf是只有一个任务执行完成，无论是正常执行或者执行异常，都会执行cf4，cf4.get的结果就是已执行完成的任务的执行结果*

## Redisson

* 实现各种分布式锁的一种方法。

## 为什么要用消息队列

### 业务解耦

* 一个事务只关心核心流程，需要依赖其他事情但是不那么重要的时候，有通知即可，无需等待结果啊。
* 比如：订单支付成功，给用户增加积分

### 最终一致性

* 用**记录**和**补偿**的方式来处理。
* 在做所有的不确定事情之前，先把事情记录下来，然后去做不确定的事，它的结果通常分为三种：成功，失败或者不确定；如果成功，我们就可以把记录的东西清理掉，对于失败和不确定，我们可以采用定时任务的方式把所有失败的事情重新做一遍直到成功为止。
* 银行转账
* 消息重复消费和幂等

### 广播

* 新业务接入只要订阅相关消息，自己处理就好了

### 错峰与流控

* 利用消息队列，转储两个系统的通信内容，在下游系统有能力处理这些消息的时候再处理这些消息
* 对于强事务而且延迟敏感的，RPC优于消息队列

## Tomcat优化

### Tomcat运行模式

* bio模式
* nio模式
* apr模式

## PV、UV、VV、IP

### 什么是PV

* PV即Page View，网站浏览量，指页面浏览的次数，用以衡量网站用户访问的网页数量。
* 用户每次打开一个页面便记录1次PV，多次打开同一页面则浏览量累计。
* PV是指页面刷新的次数，每一次页面刷新，就算做一次PV流量。
* 度量方法就是从浏览器发出一个对网络服务器的请求（Request），网络服务器接到这个请求后，会将该请求对应的一个网页（Page）发送给浏览器，从而产生了一个PV。那么在这里只要是这个请求发送给了浏览器，无论这个页面是否完全打开（下载完成），那么都是应当计为1个PV。

### 什么是UV

* UV即Unique Visitor，独立访客数，指一天内访问某站点的人数，以cookie或者Token为依据。
* 1天内同一访客的多次访问只记录为一个访客。通过IP和cookie是判断UV值的两种方式。

### 什么是VV

* VV即Visit View，访客访问的次数，用以记录所有访客一天内访问网站的次数。
* 当访客完成所有的浏览并最终关掉该网站的所有页面时，便完成了一次访问，同一访客一天内可能有多次访问行为，访问次数累计。

### 什么是IP

* IP即独立IP数，指一天内使用不同IP地址的用户访问网站的次数，同一IP无论访问了几个页面，独立的IP数均为1。

## 局部变量为什么是线程安全的

* 方法调用就是一个入栈和出栈的过程，每个方法都有自己独立的栈帧。
* 局部变量的作用域在方法内部，当方法执行完，局部变量也就没用了。
* 局部变量就是存放在调用栈里了。
* 每个线程都有自己独立的调用栈，局部变量保存在线程各自的调用栈里，不会共享，自然也就不存在并发问题。

